{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "797beb80-8e0a-4d07-b77f-67e60a000e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Player import Player\n",
    "from Trainer import Trainer\n",
    "from TetrisModel import TetrisModel\n",
    "from Pretrainer import Pretrainer\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b489fac7-4661-4921-bf2f-c27b77d68308",
   "metadata": {},
   "outputs": [],
   "source": [
    "piece_dim = 8\n",
    "key_dim = 12\n",
    "depth = 16\n",
    "gamma = 0.99\n",
    "lam = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18e02bc9-ddfa-4da9-9186-26d1a6ddbc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use lambda instead of gamma to immitate shape of gae without value predictions\n",
    "pretrainer = Pretrainer(gamma=lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f55a2a7-a685-4e03-bf63-32ca62b49a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "players_data = pretrainer._load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89477f84-bf5f-4ae2-bc25-88e464c0c7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pretrainer._load_dset(players_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bb7200b-3bd1-4c89-a760-ae040a0993f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_len = pretrainer._max_len\n",
    "max_len = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c086f18-2d08-4af8-8072-06bb186463bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Caching\n"
     ]
    }
   ],
   "source": [
    "gt_dset = pretrainer._cache_dset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f98471d2-7bdc-41d1-82c1-ec09f752b5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = TetrisModel(piece_dim=piece_dim,\n",
    "                    key_dim=key_dim,\n",
    "                    depth=depth,\n",
    "                    num_heads=4,\n",
    "                    num_layers=4,\n",
    "                    max_length=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e164709b-c4b7-4335-b3d2-c92fa2460936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tetris_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential (Sequential)     (1, 70, 16)               4800      \n",
      "                                                                 \n",
      " seq_embedding (SeqEmbedding  multiple                 128       \n",
      " )                                                               \n",
      "                                                                 \n",
      " seq_embedding_1 (SeqEmbeddi  multiple                 192       \n",
      " ng)                                                             \n",
      "                                                                 \n",
      " pdec_0 (DecoderLayer)       multiple                  9776      \n",
      "                                                                 \n",
      " pdec_1 (DecoderLayer)       multiple                  9776      \n",
      "                                                                 \n",
      " pdec_2 (DecoderLayer)       multiple                  9776      \n",
      "                                                                 \n",
      " pdec_3 (DecoderLayer)       multiple                  9776      \n",
      "                                                                 \n",
      " actor_dec_0 (DecoderLayer)  multiple                  9776      \n",
      "                                                                 \n",
      " actor_dec_1 (DecoderLayer)  multiple                  9776      \n",
      "                                                                 \n",
      " actor_dec_2 (DecoderLayer)  multiple                  9776      \n",
      "                                                                 \n",
      " actor_dec_3 (DecoderLayer)  multiple                  9776      \n",
      "                                                                 \n",
      " critic_dec_0 (DecoderLayer)  multiple                 9776      \n",
      "                                                                 \n",
      " critic_dec_1 (DecoderLayer)  multiple                 9776      \n",
      "                                                                 \n",
      " critic_dec_2 (DecoderLayer)  multiple                 9776      \n",
      "                                                                 \n",
      " critic_dec_3 (DecoderLayer)  multiple                 9776      \n",
      "                                                                 \n",
      " actor_top (Dense)           multiple                  204       \n",
      "                                                                 \n",
      " critic_top (Dense)          multiple                  17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,653\n",
      "Trainable params: 122,653\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " <tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 1,  6, 12])>,\n",
       " <tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 6, 1])>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits, values = agent((tf.random.uniform((1, 28, 10, 1)),\n",
    "                        tf.random.uniform((1, 7), minval=0, maxval=8, dtype=tf.int32),\n",
    "                        tf.random.uniform((1, max_len-1), minval=0, maxval=key_dim, dtype=tf.int32)))\n",
    "agent.summary(), tf.shape(logits), tf.shape(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e2ee521-f5c4-49b3-ab1f-149b3cfd23f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_optimizer = keras.optimizers.Adam(learning_rate=1e-6)\n",
    "agent.compile(optimizer=agent_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a581097-bad1-4da6-a805-18ef8aa6a109",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_agent = TetrisModel(piece_dim=piece_dim,\n",
    "                        key_dim=key_dim,\n",
    "                        depth=depth,\n",
    "                        num_heads=4,\n",
    "                        num_layers=4,\n",
    "                        max_length=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28f337c3-e3ca-4d56-88a4-37034f18287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, values = agent((tf.random.uniform((1, 28, 10, 1)),\n",
    "                        tf.random.uniform((1, 7), minval=0, maxval=8, dtype=tf.int32),\n",
    "                        tf.random.uniform((1, max_len-1), minval=0, maxval=key_dim, dtype=tf.int32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "577b693b-237f-48dc-ac8a-fd6e783ef902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x1894cb74190>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.load_weights('agent_weights/agent_finetuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84d64bd0-cbd4-4819-b458-963a0e4b33bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x18c31327a90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_agent.load_weights('agent_weights/agent_finetuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fca78dde-149a-4878-a274-0d3e48cc46ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a201c9-b2bd-4372-8233-604acf9c2e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, accs = pretrainer.train(agent, gt_dset, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b46352d-ba40-408c-a269-e9f72a85d410",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.plot(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cac6025f-b73f-4fe5-a091-4b324afdd72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "YOU SURE????? y\n"
     ]
    }
   ],
   "source": [
    "if 'y' in input('YOU SURE?????'):\n",
    "    agent.save_weights('agent_weights/agent_finetuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4de19b9-6807-456e-8fae-4e7809e2c094",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b6063e7-6da9-4ce9-aef5-016dbd564d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = keras.optimizers.Adam(learning_rate=1e-6), keras.optimizers.Adam(learning_rate=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54251d5e-959b-44d0-a390-e07bd721f3e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:igs16ly5) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.045 MB of 0.045 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>actor_loss</td><td>▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▂▂▂▂▁</td></tr><tr><td>critic_loss</td><td>▅▄▄▅▇▅▅▅▂▅▅▅▇▃▇▆▄▅▅▆▅▄▇▆▆▆▆▂▆▇▃▇▃▆█▁▆▅▆▃</td></tr><tr><td>kl_penalty</td><td>▅▅▂▅▄▃▂▆▄█▃▆▃▁▄▅▃▁▂▅▂▁▂▂▁▂▄▃▄▅▅▁▂▄▅▇▄▂▂▂</td></tr><tr><td>reward</td><td>▄▄▅▄▃▅▁▅▃▁▃▇▅▆▅▄▄▆▆▇▃▄▁▂▅▇▁▄█▆▇▇▅▇▄▄▁▄▇▃</td></tr><tr><td>reward_per_piece</td><td>▃▃▃▁▅▁▃▂▄▃▂▂▃▁█▃▄▂▃▁▄▃▃▂▄▂▂▅▃▂▂▁▃▁▃▃▁▄▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>actor_loss</td><td>1.3012</td></tr><tr><td>critic_loss</td><td>0.49671</td></tr><tr><td>kl_penalty</td><td>0.04753</td></tr><tr><td>reward</td><td>6.25</td></tr><tr><td>reward_per_piece</td><td>0.03788</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">breezy-frost-126</strong> at: <a href='https://wandb.ai/michaelsherrick/Tetris/runs/igs16ly5' target=\"_blank\">https://wandb.ai/michaelsherrick/Tetris/runs/igs16ly5</a><br/> View project at: <a href='https://wandb.ai/michaelsherrick/Tetris' target=\"_blank\">https://wandb.ai/michaelsherrick/Tetris</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241027_014649-igs16ly5\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:igs16ly5). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\micha\\Python Programs\\Reinforcement\\QTris\\wandb\\run-20241027_023452-xg169wlq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/michaelsherrick/Tetris/runs/xg169wlq' target=\"_blank\">absurd-darkness-127</a></strong> to <a href='https://wandb.ai/michaelsherrick/Tetris' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/michaelsherrick/Tetris' target=\"_blank\">https://wandb.ai/michaelsherrick/Tetris</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/michaelsherrick/Tetris/runs/xg169wlq' target=\"_blank\">https://wandb.ai/michaelsherrick/Tetris/runs/xg169wlq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(model=agent,\n",
    "                  ref_model=ref_agent,\n",
    "                  optimizers=optimizers,\n",
    "                  max_len=max_len,\n",
    "                  gamma=gamma,\n",
    "                  lam=lam,\n",
    "                  max_episode_steps=100,\n",
    "                  buffer_cap=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de9c0d5b-64c3-45eb-bb30-aad98833f7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done filling replay buffer\n"
     ]
    }
   ],
   "source": [
    "trainer.fill_replay_buffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278275a9-3b05-4fa5-9003-32bd6e504faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Gen: 1\t|\tAvg Reward: 0.0\t|\tTotal Reward: 7.1\t|\n",
      "Current Gen: 2\t|\tAvg Reward: 0.0\t|\tTotal Reward: 7.4\t|9\t|\t\n",
      "Current Gen: 3\t|\tAvg Reward: 0.0\t|\tTotal Reward: 5.5\t|4\t|\t\n",
      "Current Gen: 4\t|\tAvg Reward: 0.0\t|\tTotal Reward: 9.8\t|5\t|\t\n",
      "Current Gen: 5\t|\tAvg Reward: 0.0\t|\tTotal Reward: 7.5\t|6\t|\t\n",
      "Current Gen: 6\t|\tAvg Reward: 0.0\t|\tTotal Reward: 13.7\t|\t|\t\n",
      "Current Gen: 7\t|\tAvg Reward: 0.0\t|\tTotal Reward: 13.0\t|\t|\t\n",
      "Current Gen: 8\t|\tAvg Reward: 0.0\t|\tTotal Reward: 13.2\t|\t|\t\n",
      "Current Gen: 9\t|\tAvg Reward: 0.0\t|\tTotal Reward: 7.0\t|0\t|\t\n",
      "Current Gen: 10\t|\tAvg Reward: 0.0\t|\tTotal Reward: 7.8\t|\t|\t\n",
      "Current Gen: 11\t|\tAvg Reward: 0.0\t|\tTotal Reward: 3.7\t|\t|\t\n",
      "Current Gen: 12\t|\tAvg Reward: 0.0\t|\tTotal Reward: 8.8\t|\t|\t\n",
      "Current Gen: 13\t|\tAvg Reward: 0.0\t|\tTotal Reward: 3.5\t|\t|\t\n",
      "Current Gen: 14\t|\tAvg Reward: 0.0\t|\tTotal Reward: 10.8\t||\t\n",
      "Current Gen: 15\t|\tAvg Reward: 0.0\t|\tTotal Reward: 11.6\t||\t\n",
      "Current Gen: 16\t|\tAvg Reward: 0.0\t|\tTotal Reward: 6.5\t|\t|\t\n",
      "Current Gen: 17\t|\tAvg Reward: 0.0\t|\tTotal Reward: 8.3\t|\t|\t\n",
      "Current Gen: 18\t|\tAvg Reward: 0.0\t|\tTotal Reward: 15.0\t||\t\n",
      "Current Gen: 19\t|\tAvg Reward: 0.0\t|\tTotal Reward: 9.0\t|6\t|\t\n",
      "Current Gen: 20\t|\tAvg Reward: 0.0\t|\tTotal Reward: 6.8\t|\t|\t\n",
      "Current Gen: 21\t|\tAvg Reward: 0.0\t|\tTotal Reward: 8.3\t|\t|\t\n",
      "Current Gen: 22\t|\tAvg Reward: 0.0\t|\tTotal Reward: 8.3\t|\t|\t\n",
      "Current Gen: 23\t|\tAvg Reward: 0.0\t|\tTotal Reward: 15.3\t||\t\n",
      "Current Gen: 24\t|\tAvg Reward: 0.0\t|\tTotal Reward: 6.4\t|\t|\t\n",
      "Current Gen: 25\t|\tAvg Reward: 0.0\t|\tTotal Reward: 10.7\t||\t\n",
      "Current Gen: 26\t|\tAvg Reward: 0.0\t|\tTotal Reward: 14.2\t||\t\n",
      "Current Gen: 27\t|\tAvg Reward: 0.0\t|\tTotal Reward: 4.1\t|\t|\t\n",
      "Current Gen: 28\t|\tAvg Reward: 0.0\t|\tTotal Reward: 10.6\t||\t\n",
      "Current Gen: 29\t|\tAvg Reward: 0.0\t|\tTotal Reward: 8.6\t|\t|\t\n",
      "Current Gen: 30\t|\tAvg Reward: 0.0\t|\tTotal Reward: 5.9\t|\t|\t\n",
      "Current Gen: 31\t|\tAvg Reward: 0.0\t|\tTotal Reward: 5.6\t|\t|\t\n",
      "Current Gen: 32\t|\tAvg Reward: 0.0\t|\tTotal Reward: 7.6\t|\t|\t\n",
      "Current Gen: 33\t|\tAvg Reward: 0.0\t|\tTotal Reward: 5.3\t|\t|\t\n",
      "Current Gen: 34\t|\tAvg Reward: 0.0\t|\tTotal Reward: 11.6\t||\t\n",
      "Current Gen: 35\t|\tAvg Reward: 0.0\t|\tTotal Reward: 5.0\t|\t|\t\n",
      "Current Gen: 36\t|\tAvg Reward: 0.0\t|\tTotal Reward: 11.8\t||\t\n",
      "Current Gen: 37\t|\tAvg Reward: 0.0\t|\tTotal Reward: 12.5\t||\t\n",
      "Current Gen: 38\t|\tAvg Reward: 0.0\t|\tTotal Reward: 15.2\t||\t\n",
      "Current Gen: 39\t|\tAvg Reward: 0.0\t|\tTotal Reward: 12.7\t||\t\n",
      "Current Gen: 40\t|\tAvg Reward: 0.0\t|\tTotal Reward: 6.3\t|\t|\t\n",
      "Current Gen: 41\t|\tAvg Reward: 0.0\t|\tTotal Reward: 3.7\t|\t|\t\n",
      "Current Gen: 42\t|\tAvg Reward: 0.0\t|\tTotal Reward: 12.4\t||\t\n",
      "Current Gen: 43\t|\tAvg Reward: 0.0\t|\tTotal Reward: 12.8\t||\t\n",
      "Current Gen: 44\t|\tAvg Reward: 0.0\t|\tTotal Reward: 3.2\t|\t|\t\n",
      "Current Gen: 45\t|\tAvg Reward: 0.0\t|\tTotal Reward: 10.7\t||\t\n",
      "Current Gen: 46\t|\tAvg Reward: 0.0\t|\tTotal Reward: 12.3\t||\t\n",
      "Current Gen: 47\t|\tAvg Reward: 0.0\t|\tTotal Reward: 8.5\t|\t|\t\n",
      "Current Gen: 48\t|\tAvg Reward: 0.0\t|\tTotal Reward: 12.8\t||\t\n",
      "Current Gen: 49\t|\tAvg Reward: 0.0\t|\tTotal Reward: 10.9\t||\t\n",
      "Current Gen: 50\t|\tAvg Reward: 0.0\t|\tTotal Reward: 8.8\t|\t|\t\n",
      "Current Gen: 51\t|\tAvg Reward: 0.0\t|\tTotal Reward: 10.6\t||\t\n",
      "Current Gen: 52\t|\tAvg Reward: 0.0\t|\tTotal Reward: 13.8\t||\t\n",
      "Current Gen: 53\t|\tAvg Reward: 0.0\t|\tTotal Reward: 4.6\t|0\t|\t\n",
      "Current Gen: 54\t|\tAvg Reward: 0.0\t|\tTotal Reward: 4.8\t|\t|\t\n",
      "Current Gen: 55\t|\tAvg Reward: 0.0\t|\tTotal Reward: 13.7\t||\t\n",
      "Current Gen: 56\t|\tAvg Reward: 0.0\t|\tTotal Reward: 10.7\t||\t\n",
      "Current Gen: 57\t|\tAvg Reward: 0.0\t|\tTotal Reward: 8.6\t|\t|\t\n",
      "Current Gen: 58\t|\tAvg Reward: 0.0\t|\tTotal Reward: 4.9\t|\t|\t\n",
      "Current Gen: 59\t|\tAvg Reward: 0.0\t|\tTotal Reward: 15.0\t||\t\n",
      "Current Gen: 60\t|\tAvg Reward: 0.0\t|\tTotal Reward: 9.5\t|\t|\t\n",
      "Current Gen: 61\t|\tAvg Reward: 0.0\t|\tTotal Reward: 10.3\t||\t\n",
      "Current Gen: 62\t|\tAvg Reward: 0.0\t|\tTotal Reward: 4.8\t|\t|\t\n",
      "Current Gen: 63\t|\tAvg Reward: 0.0\t|\tTotal Reward: 10.4\t||\t\n",
      "Current Gen: 64\t|\tAvg Reward: 0.0\t|\tTotal Reward: 14.0\t||\t\n",
      "Current Gen: 65\t|\tAvg Reward: 0.0\t|\tTotal Reward: 9.2\t|2\t|\t\n",
      "Current Gen: 66\t|\tAvg Reward: 0.0\t|\tTotal Reward: 13.0\t|\t|\t\n",
      "Current Gen: 67\t|\tAvg Reward: 0.0\t|\tTotal Reward: 7.0\t|\t|\t\n",
      "Current Gen: 68\t|\tAvg Reward: 0.0\t|\tTotal Reward: 4.7\t|\t|\t\n",
      "Current Gen: 69\t|\tAvg Reward: 0.0\t|\tTotal Reward: 15.8\t||\t\n",
      "Current Gen: 70\t|\tAvg Reward: 0.0\t|\tTotal Reward: 8.9\t|\t|\t\n",
      "Current Gen: 71\t|\tAvg Reward: 0.0\t|\tTotal Reward: 14.0\t||\t\n",
      "Current Gen: 72\t|\tAvg Reward: 0.0\t|\tTotal Reward: 13.1\t||\t\n",
      "Current Gen: 73\t|\tAvg Reward: 0.0\t|\tTotal Reward: 6.7\t|\t|\t\n",
      "Current Gen: 74\t|\tAvg Reward: 0.0\t|\tTotal Reward: 7.9\t|\t|\t\n",
      "Current Gen: 75\t|\tAvg Reward: 0.0\t|\tTotal Reward: 8.5\t|\t|\t\n",
      "Current Gen: 76\t|\tAvg Reward: 0.0\t|\tTotal Reward: 8.0\t|\t|\t\n",
      "Current Gen: 77\t|\tAvg Reward: 0.0\t|\tTotal Reward: 15.8\t||\t\n",
      "Current Gen: 78\t|\tAvg Reward: 0.0\t|\tTotal Reward: 11.4\t||\t\n",
      "Current Gen: 79\t|\tAvg Reward: 0.0\t|\tTotal Reward: 13.5\t||\t\n",
      "Current Gen: 80\t|\tAvg Reward: 0.0\t|\tTotal Reward: 7.0\t|\t|\t\n",
      "Current Gen: 81\t|\tAvg Reward: 0.0\t|\tTotal Reward: 6.6\t|\t|\t\n",
      "Current Gen: 82\t|\tAvg Reward: 0.0\t|\tTotal Reward: 7.7\t|\t|\t\n",
      "Current Gen: 83\t|\tAvg Reward: 0.0\t|\tTotal Reward: 5.9\t|\t|\t\n",
      "Current Gen: 84\t|\tAvg Reward: 0.0\t|\tTotal Reward: 12.6\t||\t\n",
      "Actor Loss: 0.23\t|\tKL Penalty: 0.04\t|\tCritic Loss: 0.49\t|\t"
     ]
    }
   ],
   "source": [
    "trainer.train(gens=10000, train_steps=10, training_actor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c04c14f-8671-4168-8eb3-f10747e66ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_data = trainer.player.run_episode(agent, max_steps=1000, greedy=True, renderer=trainer.renderer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7e2f169-5696-4f82-940a-d577891ea542",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_boards, episode_pieces, episode_inputs, episode_actions, episode_valid, episode_probs, episode_values, episode_rewards = episode_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f72f64fa-a6f0-4c69-ada5-2cc805c05006",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_advantages, episode_returns = trainer._compute_gae(episode_values, episode_rewards, trainer.gamma, trainer.lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e94791d9-14a5-42a2-bdd5-325e70a72614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=25.850002>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(episode_returns, label='Returns')\n",
    "ax.plot(episode_rewards, label='Rewards')\n",
    "ax.plot(episode_values, label='Values')\n",
    "ax.plot(episode_advantages, label='Advantages')\n",
    "ax.legend()\n",
    "tf.reduce_sum(episode_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01a0978-ad32-44dd-b8be-8254c1098e7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
