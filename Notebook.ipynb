{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "797beb80-8e0a-4d07-b77f-67e60a000e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Player import Player\n",
    "from Trainer import Trainer\n",
    "from TetrisModel import TetrisModel\n",
    "from Pretrainer import Pretrainer\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b489fac7-4661-4921-bf2f-c27b77d68308",
   "metadata": {},
   "outputs": [],
   "source": [
    "piece_dim = 8\n",
    "key_dim = 12\n",
    "depth = 16\n",
    "gamma = 0.99\n",
    "lam = 0.95\n",
    "temperature = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18e02bc9-ddfa-4da9-9186-26d1a6ddbc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use lambda instead of gamma to immitate shape of gae without value predictions\n",
    "# pretrainer = Pretrainer(gamma=lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f55a2a7-a685-4e03-bf63-32ca62b49a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# players_data = pretrainer._load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89477f84-bf5f-4ae2-bc25-88e464c0c7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrainer._load_dset(players_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2bb7200b-3bd1-4c89-a760-ae040a0993f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_len = pretrainer._max_len\n",
    "max_len = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1c086f18-2d08-4af8-8072-06bb186463bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_dset = pretrainer._cache_dset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f98471d2-7bdc-41d1-82c1-ec09f752b5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = TetrisModel(piece_dim=piece_dim,\n",
    "                    key_dim=key_dim,\n",
    "                    depth=depth,\n",
    "                    num_heads=4,\n",
    "                    num_layers=4,\n",
    "                    max_length=max_len,\n",
    "                    out_dim=key_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2e2ee521-f5c4-49b3-ab1f-149b3cfd23f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent_optimizer = keras.optimizers.Adam(learning_rate=1e-5)\n",
    "agent.compile(optimizer=agent_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e164709b-c4b7-4335-b3d2-c92fa2460936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tetris_model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_27 (Sequential)  (1, 70, 16)               4800      \n",
      "                                                                 \n",
      " seq_embedding_6 (SeqEmbeddi  multiple                 128       \n",
      " ng)                                                             \n",
      "                                                                 \n",
      " seq_embedding_7 (SeqEmbeddi  multiple                 192       \n",
      " ng)                                                             \n",
      "                                                                 \n",
      " piece_dec_0 (DecoderLayer)  multiple                  9776      \n",
      "                                                                 \n",
      " piece_dec_1 (DecoderLayer)  multiple                  9776      \n",
      "                                                                 \n",
      " piece_dec_2 (DecoderLayer)  multiple                  9776      \n",
      "                                                                 \n",
      " piece_dec_3 (DecoderLayer)  multiple                  9776      \n",
      "                                                                 \n",
      " key_dec_0 (DecoderLayer)    multiple                  9776      \n",
      "                                                                 \n",
      " key_dec_1 (DecoderLayer)    multiple                  9776      \n",
      "                                                                 \n",
      " key_dec_2 (DecoderLayer)    multiple                  9776      \n",
      "                                                                 \n",
      " key_dec_3 (DecoderLayer)    multiple                  9776      \n",
      "                                                                 \n",
      " model_top (Dense)           multiple                  204       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 83,532\n",
      "Trainable params: 83,532\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, <tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 1, 10, 12])>)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = agent((tf.random.uniform((1, 28, 10, 1)),\n",
    "                tf.random.uniform((1, 7), minval=0, maxval=8, dtype=tf.int32),\n",
    "                tf.random.uniform((1, max_len), minval=0, maxval=key_dim, dtype=tf.int32)))\n",
    "agent.summary(), tf.shape(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6d393408-7d44-4907-b253-8cf2178ac84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "critic = TetrisModel(piece_dim=piece_dim,\n",
    "                     key_dim=key_dim,\n",
    "                     depth=depth,\n",
    "                     num_heads=4,\n",
    "                     num_layers=4,\n",
    "                     max_length=max_len,\n",
    "                     out_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8209a038-3b17-40e4-bdfa-d8ff3c8a7248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# critic_optimizer = keras.optimizers.Adam(learning_rate=1e-5)\n",
    "critic.compile(optimizer=critic_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "53d1d4e9-760b-47b0-948d-15010c16f820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TetrisModel.call at 0x0000020461375EE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Model: \"tetris_model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_36 (Sequential)  (1, 70, 16)               4800      \n",
      "                                                                 \n",
      " seq_embedding_8 (SeqEmbeddi  multiple                 128       \n",
      " ng)                                                             \n",
      "                                                                 \n",
      " seq_embedding_9 (SeqEmbeddi  multiple                 192       \n",
      " ng)                                                             \n",
      "                                                                 \n",
      " piece_dec_0 (DecoderLayer)  multiple                  9776      \n",
      "                                                                 \n",
      " piece_dec_1 (DecoderLayer)  multiple                  9776      \n",
      "                                                                 \n",
      " piece_dec_2 (DecoderLayer)  multiple                  9776      \n",
      "                                                                 \n",
      " piece_dec_3 (DecoderLayer)  multiple                  9776      \n",
      "                                                                 \n",
      " key_dec_0 (DecoderLayer)    multiple                  9776      \n",
      "                                                                 \n",
      " key_dec_1 (DecoderLayer)    multiple                  9776      \n",
      "                                                                 \n",
      " key_dec_2 (DecoderLayer)    multiple                  9776      \n",
      "                                                                 \n",
      " key_dec_3 (DecoderLayer)    multiple                  9776      \n",
      "                                                                 \n",
      " model_top (Dense)           multiple                  17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 83,345\n",
      "Trainable params: 83,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, <tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 1, 10,  1])>)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = critic((tf.random.uniform((1, 28, 10, 1)),\n",
    "                 tf.random.uniform((1, 7), minval=0, maxval=8, dtype=tf.int32),\n",
    "                 tf.random.uniform((1, max_len), minval=0, maxval=key_dim, dtype=tf.int32)))\n",
    "critic.summary(), tf.shape(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "577b693b-237f-48dc-ac8a-fd6e783ef902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x2046bfd6fd0>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.load_weights('agent_weights_small/agent_finetuned_4712')\n",
    "critic.load_weights('critic_weights_small/critic_finetuned_4712')\n",
    "# with open('agent_weights_small/optimizer.pkl', 'rb') as f:\n",
    "#     weight_values = pickle.load(f)\n",
    "# agent_optimizer.set_weights(weight_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a581097-bad1-4da6-a805-18ef8aa6a109",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_agent = TetrisModel(piece_dim=piece_dim,\n",
    "                        key_dim=key_dim,\n",
    "                        depth=depth,\n",
    "                        num_heads=4,\n",
    "                        num_layers=4,\n",
    "                        max_length=max_len,\n",
    "                        out_dim=key_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28f337c3-e3ca-4d56-88a4-37034f18287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = ref_agent((tf.random.uniform((1, 28, 10, 1)),\n",
    "                    tf.random.uniform((1, 7), minval=0, maxval=8, dtype=tf.int32),\n",
    "                    tf.random.uniform((1, max_len), minval=0, maxval=key_dim, dtype=tf.int32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "84d64bd0-cbd4-4819-b458-963a0e4b33bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x2017d04edc0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_agent.load_weights('agent_weights_small/agent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fca78dde-149a-4878-a274-0d3e48cc46ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69a201c9-b2bd-4372-8233-604acf9c2e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actor_losses, critic_losses, accs = pretrainer.train(agent, critic, gt_dset, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b46352d-ba40-408c-a269-e9f72a85d410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(actor_losses)\n",
    "# plt.plot(critic_losses)\n",
    "# plt.plot(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31dfd085-4b1f-4f7b-9eeb-c489a5e061fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'y' in input('YOU SURE?????'):\n",
    "#     ref_agent.save_weights('agent_weights_small/agent_reference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4de19b9-6807-456e-8fae-4e7809e2c094",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "54251d5e-959b-44d0-a390-e07bd721f3e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:t6ykzzok) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.025 MB of 0.025 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>critic_loss</td><td>▂▂▁▂▁▂▂▄▄▃▂▁▄▂▃▅▆▃▅▂█▄▄▃▃▆▃▅▄▂▂▄▂▅▅▃▃▅▃▆</td></tr><tr><td>kl_penalty</td><td>▃▅▁█▅▂▄▄▆▅▇▄▇▅▃▂▅▆▃▃▆▅▇▅▆▅▆▄▂▅▄▇▇▆▄▅▆▅█▇</td></tr><tr><td>ppo_loss</td><td>▅▂▃▆▇▂▄▃▅▅▆▄▇▆▄▃▄▆▂▅▂▁▄█▄▇█▆▅▄▃▆▅▆▇▇▄▂▁▄</td></tr><tr><td>reward</td><td>▂▅▂▂▃▆▇▆▁▃▃▄▁▁▄▄▁▆▄▃▅█▁▅▄▃▇▇▅█▄▂▄▇▄▄▇▆█▆</td></tr><tr><td>reward_per_piece</td><td>▄▃▁▃▄▃▂▁▅▃▂▄▆▄▄▄▆▄▅▄▅▇▅▂▂▇▂▅▅▅▄▅▂▄█▅▄▆▄▄</td></tr><tr><td>unclipped_proportion</td><td>▁▃▃▂▅▄▆▄▄▂▄▄▁▃▆▄▄▅▄▅▃▄▃▅▆▃▆▄▅▄▃▄▆▅▄█▅▄▄▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>critic_loss</td><td>0.77691</td></tr><tr><td>kl_penalty</td><td>0.05864</td></tr><tr><td>ppo_loss</td><td>0.07835</td></tr><tr><td>reward</td><td>7.25</td></tr><tr><td>reward_per_piece</td><td>0.0725</td></tr><tr><td>unclipped_proportion</td><td>0.81481</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">faithful-bush-207</strong> at: <a href='https://wandb.ai/michaelsherrick/Tetris/runs/t6ykzzok' target=\"_blank\">https://wandb.ai/michaelsherrick/Tetris/runs/t6ykzzok</a><br/> View project at: <a href='https://wandb.ai/michaelsherrick/Tetris' target=\"_blank\">https://wandb.ai/michaelsherrick/Tetris</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241105_013515-t6ykzzok\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:t6ykzzok). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\micha\\Python Programs\\Reinforcement\\QTris\\wandb\\run-20241105_132609-yjshqz9p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/michaelsherrick/Tetris/runs/yjshqz9p' target=\"_blank\">glad-planet-208</a></strong> to <a href='https://wandb.ai/michaelsherrick/Tetris' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/michaelsherrick/Tetris' target=\"_blank\">https://wandb.ai/michaelsherrick/Tetris</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/michaelsherrick/Tetris/runs/yjshqz9p' target=\"_blank\">https://wandb.ai/michaelsherrick/Tetris/runs/yjshqz9p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(agent=agent,\n",
    "                  critic=critic,\n",
    "                  ref_model=ref_agent,\n",
    "                  max_len=max_len,\n",
    "                  gamma=gamma,\n",
    "                  lam=lam,\n",
    "                  temperature=temperature,\n",
    "                  max_episode_steps=100,\n",
    "                  buffer_cap=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "de9c0d5b-64c3-45eb-bb30-aad98833f7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done filling replay buffer"
     ]
    }
   ],
   "source": [
    "trainer.fill_replay_buffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "39b4f4e4-2ce5-4bd4-8e9d-930426e4a60d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPO Loss: 0.08\t|\tKL Penalty: 0.06\t|\tCritic Loss: 0.78\t|\t"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18372\\3238984189.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_actor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'agent_weights_small/agent_finetuned_{trainer.wandb_run.step}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mcritic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'critic_weights_small/critic_finetuned{trainer.wandb_run.step}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Python Programs\\Reinforcement\\QTris\\Trainer.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, gens, train_steps, training_actor)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mgen\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[1;31m# Run episode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m             episode_data = self.player.run_episode(self.agent, self.critic, max_steps=self.max_episode_steps,\n\u001b[0m\u001b[0;32m    171\u001b[0m                                                    greedy=False, temperature=self.temp, renderer=self.renderer)\n\u001b[0;32m    172\u001b[0m             \u001b[0mepisode_boards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepisode_pieces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepisode_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepisode_probs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepisode_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepisode_rewards\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepisode_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m             \u001b[0mepisode_advantages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepisode_returns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_gae\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepisode_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepisode_rewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Python Programs\\Reinforcement\\QTris\\Player.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, agent, critic, max_steps, greedy, temperature, renderer)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpiece\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mterminated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m             \u001b[0mboard_obs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m             \u001b[0mpiece_obs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpiece\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0minp_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0mkey_chars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1180\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1181\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mOpDispatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(x, dtype, name)\u001b[0m\n\u001b[0;32m   1002\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1003\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1004\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_complex\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Casting complex to real discards imaginary part.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1006\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(x, DstT, Truncate, name)\u001b[0m\n\u001b[0;32m   1998\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1999\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2000\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2001\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2002\u001b[1;33m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2003\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2004\u001b[0m       return cast_eager_fallback(\n\u001b[0;32m   2005\u001b[0m           x, DstT=DstT, Truncate=Truncate, name=name, ctx=_ctx)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    trainer.train(gens=100, train_steps=5, training_actor=True)\n",
    "    agent.save_weights(f'agent_weights_small/agent_finetuned_{trainer.wandb_run.step}')\n",
    "    critic.save_weights(f'critic_weights_small/critic_finetuned_{trainer.wandb_run.step}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "cac6025f-b73f-4fe5-a091-4b324afdd72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "YOU SURE????? y\n"
     ]
    }
   ],
   "source": [
    "if 'y' in input('YOU SURE?????'):\n",
    "    agent.save_weights(f'agent_weights_small/agent_finetuned_{trainer.wandb_run.step}')\n",
    "    critic.save_weights(f'critic_weights_small/critic_finetuned_{trainer.wandb_run.step}')\n",
    "    \n",
    "    # symbolic_weights = getattr(agent.optimizer, 'weights')\n",
    "    # weight_values = K.batch_get_value(symbolic_weights)\n",
    "    # with open('agent_weights_small/optimizer.pkl', 'wb') as f:\n",
    "    #     pickle.dump(weight_values, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3c04c14f-8671-4168-8eb3-f10747e66ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_data = trainer.player.run_episode(agent, critic, max_steps=100, greedy=True, renderer=trainer.renderer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f7e2f169-5696-4f82-940a-d577891ea542",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_boards, episode_pieces, episode_inputs, episode_probs, episode_values, episode_rewards = episode_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f72f64fa-a6f0-4c69-ada5-2cc805c05006",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_advantages, episode_returns = trainer._compute_gae(episode_values, episode_rewards, trainer.gamma, trainer.lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e94791d9-14a5-42a2-bdd5-325e70a72614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=5.749999>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(episode_returns, label='Returns')\n",
    "ax.plot(episode_values, label='Values')\n",
    "ax.legend()\n",
    "tf.reduce_sum(episode_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1c5260fb-9eae-4bbf-8273-6fb97c3f2fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2045c13ee20>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(episode_rewards, label='Returns')\n",
    "ax.plot(episode_advantages, label='Advantages')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174dee37-94fb-4b42-af4b-b65396ca8525",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
