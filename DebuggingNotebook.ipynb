{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "797beb80-8e0a-4d07-b77f-67e60a000e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrainerSeparateParallel import Trainer\n",
    "from TetrisModel import TetrisModel\n",
    "from Pretrainer import Pretrainer\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b489fac7-4661-4921-bf2f-c27b77d68308",
   "metadata": {},
   "outputs": [],
   "source": [
    "piece_dim = 8\n",
    "key_dim = 12\n",
    "depth = 32\n",
    "gamma = 0.99\n",
    "lam = 0.95\n",
    "temperature = 1.0\n",
    "num_players = 16\n",
    "display_rows = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18e02bc9-ddfa-4da9-9186-26d1a6ddbc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrainer = Pretrainer(gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f55a2a7-a685-4e03-bf63-32ca62b49a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# players_data = pretrainer._load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89477f84-bf5f-4ae2-bc25-88e464c0c7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrainer._load_dset(players_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bb7200b-3bd1-4c89-a760-ae040a0993f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_len = pretrainer._max_len\n",
    "max_len = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c086f18-2d08-4af8-8072-06bb186463bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_dset = pretrainer._cache_dset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f98471d2-7bdc-41d1-82c1-ec09f752b5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = TetrisModel(piece_dim=piece_dim,\n",
    "                    key_dim=key_dim,\n",
    "                    depth=depth,\n",
    "                    num_heads=4,\n",
    "                    num_layers=4,\n",
    "                    max_length=max_len,\n",
    "                    out_dim=key_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e2ee521-f5c4-49b3-ab1f-149b3cfd23f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_optimizer = keras.optimizers.Adam(1e-5, clipnorm=1.5)\n",
    "agent.compile(optimizer=agent_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e164709b-c4b7-4335-b3d2-c92fa2460936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tetris_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential (Sequential)     (32, 70, 32)              37312     \n",
      "                                                                 \n",
      " seq_embedding (SeqEmbedding  multiple                 256       \n",
      " )                                                               \n",
      "                                                                 \n",
      " seq_embedding_1 (SeqEmbeddi  multiple                 384       \n",
      " ng)                                                             \n",
      "                                                                 \n",
      " piece_dec_0 (DecoderLayer)  multiple                  37984     \n",
      "                                                                 \n",
      " piece_dec_1 (DecoderLayer)  multiple                  37984     \n",
      "                                                                 \n",
      " piece_dec_2 (DecoderLayer)  multiple                  37984     \n",
      "                                                                 \n",
      " piece_dec_3 (DecoderLayer)  multiple                  37984     \n",
      "                                                                 \n",
      " key_dec_0 (DecoderLayer)    multiple                  37984     \n",
      "                                                                 \n",
      " key_dec_1 (DecoderLayer)    multiple                  37984     \n",
      "                                                                 \n",
      " key_dec_2 (DecoderLayer)    multiple                  37984     \n",
      "                                                                 \n",
      " key_dec_3 (DecoderLayer)    multiple                  37984     \n",
      "                                                                 \n",
      " model_top (Dense)           multiple                  396       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 342,220\n",
      "Trainable params: 342,220\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " <tf.Tensor: shape=(3,), dtype=int32, numpy=array([32, 10, 12])>,\n",
       " <tf.Tensor: shape=(5,), dtype=int32, numpy=array([ 4, 32,  4,  7, 70])>,\n",
       " <tf.Tensor: shape=(5,), dtype=int32, numpy=array([ 4, 32,  4, 10,  7])>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits, piece_scores, key_scores = agent((tf.random.uniform((32, 28, 10, 1)),\n",
    "                                          tf.random.uniform((32, 7), minval=0, maxval=8, dtype=tf.int32),\n",
    "                                          tf.random.uniform((32, max_len), minval=0, maxval=key_dim, dtype=tf.int32)), return_scores=True)\n",
    "agent.summary(), tf.shape(logits), tf.shape(piece_scores), tf.shape(key_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d393408-7d44-4907-b253-8cf2178ac84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "critic = TetrisModel(piece_dim=piece_dim,\n",
    "                     key_dim=key_dim,\n",
    "                     depth=depth,\n",
    "                     num_heads=4,\n",
    "                     num_layers=4,\n",
    "                     max_length=max_len,\n",
    "                     out_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8209a038-3b17-40e4-bdfa-d8ff3c8a7248",
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_optimizer = keras.optimizers.Adam(1e-5, clipnorm=1.5)\n",
    "critic.compile(optimizer=critic_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53d1d4e9-760b-47b0-948d-15010c16f820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tetris_model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_9 (Sequential)   (32, 70, 32)              37312     \n",
      "                                                                 \n",
      " seq_embedding_2 (SeqEmbeddi  multiple                 256       \n",
      " ng)                                                             \n",
      "                                                                 \n",
      " seq_embedding_3 (SeqEmbeddi  multiple                 384       \n",
      " ng)                                                             \n",
      "                                                                 \n",
      " piece_dec_0 (DecoderLayer)  multiple                  37984     \n",
      "                                                                 \n",
      " piece_dec_1 (DecoderLayer)  multiple                  37984     \n",
      "                                                                 \n",
      " piece_dec_2 (DecoderLayer)  multiple                  37984     \n",
      "                                                                 \n",
      " piece_dec_3 (DecoderLayer)  multiple                  37984     \n",
      "                                                                 \n",
      " key_dec_0 (DecoderLayer)    multiple                  37984     \n",
      "                                                                 \n",
      " key_dec_1 (DecoderLayer)    multiple                  37984     \n",
      "                                                                 \n",
      " key_dec_2 (DecoderLayer)    multiple                  37984     \n",
      "                                                                 \n",
      " key_dec_3 (DecoderLayer)    multiple                  37984     \n",
      "                                                                 \n",
      " model_top (Dense)           multiple                  33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 341,857\n",
      "Trainable params: 341,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " <tf.Tensor: shape=(3,), dtype=int32, numpy=array([32, 10,  1])>,\n",
       " <tf.Tensor: shape=(5,), dtype=int32, numpy=array([ 4, 32,  4,  7, 70])>,\n",
       " <tf.Tensor: shape=(5,), dtype=int32, numpy=array([ 4, 32,  4, 10,  7])>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values, piece_scores, key_scores = critic((tf.random.uniform((32, 28, 10, 1)),\n",
    "                                           tf.random.uniform((32, 7), minval=0, maxval=8, dtype=tf.int32),\n",
    "                                           tf.random.uniform((32, max_len), minval=0, maxval=key_dim, dtype=tf.int32)), return_scores=True)\n",
    "critic.summary(), tf.shape(values), tf.shape(piece_scores), tf.shape(key_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d8093c4-0413-4cbc-b1b9-04665b6df3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x22f9f6dab50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_checkpoint = tf.train.Checkpoint(model=agent, optim=agent.optimizer)\n",
    "agent_checkpoint.restore('agent_checkpoint/finetuned/ckpt-9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "842fbadb-0146-4d8c-b365-d60bc388cd47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x22c951c8b20>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critic_checkpoint = tf.train.Checkpoint(model=critic, optim=critic.optimizer)\n",
    "critic_checkpoint.restore('critic_checkpoint/finetuned/ckpt-9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a581097-bad1-4da6-a805-18ef8aa6a109",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_agent = TetrisModel(piece_dim=piece_dim,\n",
    "                        key_dim=key_dim,\n",
    "                        depth=depth,\n",
    "                        num_heads=4,\n",
    "                        num_layers=4,\n",
    "                        max_length=max_len,\n",
    "                        out_dim=key_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28f337c3-e3ca-4d56-88a4-37034f18287c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 1, 10, 12])>,\n",
       " <tf.Tensor: shape=(5,), dtype=int32, numpy=array([ 4,  1,  4,  7, 70])>,\n",
       " <tf.Tensor: shape=(5,), dtype=int32, numpy=array([ 4,  1,  4, 10,  7])>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits, piece_scores, key_scores = ref_agent((tf.random.uniform((1, 28, 10, 1)),\n",
    "                                              tf.random.uniform((1, 7), minval=0, maxval=8, dtype=tf.int32),\n",
    "                                              tf.random.uniform((1, max_len), minval=0, maxval=key_dim, dtype=tf.int32)), return_scores=True)\n",
    "tf.shape(logits), tf.shape(piece_scores), tf.shape(key_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84d64bd0-cbd4-4819-b458-963a0e4b33bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x22c9513fa60>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_checkpoint = tf.train.Checkpoint(model=ref_agent)\n",
    "ref_checkpoint.restore('agent_checkpoint/finetuned/ckpt-9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fca78dde-149a-4878-a274-0d3e48cc46ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69a201c9-b2bd-4372-8233-604acf9c2e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actor_losses, critic_losses, accs = pretrainer.train(agent, critic, gt_dset, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4de19b9-6807-456e-8fae-4e7809e2c094",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b46352d-ba40-408c-a269-e9f72a85d410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(actor_losses)\n",
    "# plt.plot(critic_losses)\n",
    "# plt.plot(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50f21c18-8648-4d77-89e5-667dd4ada8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent_checkpoint.save('agent_checkpoint/pretrained/ckpt')\n",
    "# critic_checkpoint.save('critic_checkpoint/pretrained/ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7373ed28-a931-491b-ae7a-13c126093a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_checkpoint = tf.train.Checkpoint(model=agent, optim=agent.optimizer)\n",
    "agent_checkpoint_manager = tf.train.CheckpointManager(agent_checkpoint, 'agent_checkpoint/finetuned', max_to_keep=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2b9b919-cb00-403c-a137-cbac0faf71d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_checkpoint = tf.train.Checkpoint(model=critic, optim=critic.optimizer)\n",
    "critic_checkpoint_manager = tf.train.CheckpointManager(critic_checkpoint, 'critic_checkpoint/finetuned', max_to_keep=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54251d5e-959b-44d0-a390-e07bd721f3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmichaelsherrick\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\micha\\Python Programs\\Reinforcement\\QTris\\wandb\\run-20241224_200650-e24ffyc1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/michaelsherrick/Tetris/runs/e24ffyc1' target=\"_blank\">fearless-wood-413</a></strong> to <a href='https://wandb.ai/michaelsherrick/Tetris' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/michaelsherrick/Tetris' target=\"_blank\">https://wandb.ai/michaelsherrick/Tetris</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/michaelsherrick/Tetris/runs/e24ffyc1' target=\"_blank\">https://wandb.ai/michaelsherrick/Tetris/runs/e24ffyc1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(agent=agent,\n",
    "                  critic=critic,\n",
    "                  ref_model=ref_agent,\n",
    "                  max_len=max_len,\n",
    "                  num_players=num_players,\n",
    "                  display_rows=display_rows,\n",
    "                  gamma=gamma,\n",
    "                  lam=lam,\n",
    "                  temperature=temperature,\n",
    "                  max_episode_steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "39b4f4e4-2ce5-4bd4-8e9d-930426e4a60d",
   "metadata": {},
   "outputs": [
    {
     "ename": "BrokenProcessPool",
     "evalue": "A process in the process pool was terminated abruptly while the future was running or pending.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m----> 3\u001b[0m         \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_actor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m         agent_checkpoint_manager\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m      5\u001b[0m         critic_checkpoint_manager\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[1;32m~\\Python Programs\\Reinforcement\\QTris\\TrainerSeparateParallel.py:150\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, gens, train_steps, training_actor)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, gens, train_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, training_actor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m gen \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(gens):\n\u001b[0;32m    148\u001b[0m         \n\u001b[0;32m    149\u001b[0m         \u001b[38;5;66;03m# Run episode\u001b[39;00m\n\u001b[1;32m--> 150\u001b[0m         episode_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_episode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcritic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_episode_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mgreedy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    152\u001b[0m         (all_episode_boards, all_episode_pieces, all_episode_inputs,\n\u001b[0;32m    153\u001b[0m          all_episode_actions, all_episode_probs, all_episode_values, all_episode_rewards) \u001b[38;5;241m=\u001b[39m episode_data\n\u001b[0;32m    155\u001b[0m         all_episode_advantages, all_episode_returns \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Python Programs\\Reinforcement\\QTris\\PlayerSeparateParallel.py:114\u001b[0m, in \u001b[0;36mPlayer.run_episode\u001b[1;34m(self, agent, critic, max_steps, greedy, temperature, renderer)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_episode\u001b[39m(\u001b[38;5;28mself\u001b[39m, agent, critic, max_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, greedy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, renderer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    113\u001b[0m     living_players \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_players))\n\u001b[1;32m--> 114\u001b[0m     all_episode_data, all_board, all_piece, all_terminated, all_last_holes, all_last_bumpiness \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parallel_start\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m    116\u001b[0m     (all_episode_boards, all_episode_pieces, all_episode_inputs,\n\u001b[0;32m    117\u001b[0m      all_episode_actions, all_episode_probs, all_episode_values, all_episode_rewards) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mall_episode_data))\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_steps):\n",
      "File \u001b[1;32m~\\Python Programs\\Reinforcement\\QTris\\PlayerSeparateParallel.py:82\u001b[0m, in \u001b[0;36mPlayer._parallel_start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ProcessPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m     80\u001b[0m     results \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_single_start, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgames)\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\concurrent\\futures\\process.py:562\u001b[0m, in \u001b[0;36m_chain_from_iterable_of_lists\u001b[1;34m(iterable)\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_chain_from_iterable_of_lists\u001b[39m(iterable):\n\u001b[0;32m    557\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;124;03m    Specialized implementation of itertools.chain.from_iterable.\u001b[39;00m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;124;03m    Each item in *iterable* should be a list.  This function is\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;124;03m    careful not to keep references to yielded objects.\u001b[39;00m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 562\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m    563\u001b[0m         element\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[0;32m    564\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m element:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\concurrent\\futures\\_base.py:609\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[0;32m    607\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 609\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    610\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    611\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m fs\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mresult(end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\concurrent\\futures\\_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\concurrent\\futures\\_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 391\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    393\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    394\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mBrokenProcessPool\u001b[0m: A process in the process pool was terminated abruptly while the future was running or pending."
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    if __name__ == '__main__':\n",
    "        trainer.train(gens=100, train_steps=100, training_actor=True)\n",
    "        agent_checkpoint_manager.save()\n",
    "        critic_checkpoint_manager.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "71adf545-825a-4222-a8a3-8293477146ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'critic_checkpoint/finetuned\\\\ckpt-9'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_checkpoint_manager.save()\n",
    "critic_checkpoint_manager.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f00ba18-99f5-41f0-9215-6d82c1e4ab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_demo('Demo.gif', max_steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c04c14f-8671-4168-8eb3-f10747e66ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_data = trainer.player.run_episode(agent, critic, max_steps=1000, greedy=True, renderer=trainer.renderer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f7e2f169-5696-4f82-940a-d577891ea542",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_boards, episode_pieces, episode_inputs, episode_actions, episode_probs, episode_values, episode_rewards = episode_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f72f64fa-a6f0-4c69-ada5-2cc805c05006",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_advantages, episode_returns = trainer._compute_gae(episode_values, episode_rewards, trainer.gamma, trainer.lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e94791d9-14a5-42a2-bdd5-325e70a72614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=154.17001>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(episode_returns, label='Returns')\n",
    "ax.plot(episode_values, label='Values')\n",
    "ax.legend()\n",
    "tf.reduce_sum(episode_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c5260fb-9eae-4bbf-8273-6fb97c3f2fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x22e8b5b1fd0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(episode_rewards, label='Rewards')\n",
    "ax.plot(episode_advantages, label='Advantages')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c77a526-2a60-4f87-8d73-e9d1f8c292b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.357 MB of 0.357 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>critic_loss</td><td>▂▁▃▁▃▁▁▁▃▄▁▁▂▄▁▅▁▁▁▂▁▁▄▂▁▁▁▂▃▁▁█▅▂▅▃▁▁▁▁</td></tr><tr><td>entropy</td><td>▆▅▆▆▆▄▆▆▄▆▆▅▇▇▅▅▁▅▃▆▅▃▅▇██▇▇▆█▅██▅▄▆▇█▅▅</td></tr><tr><td>kl_div</td><td>▄▂▄▂▃▄▂▂▁▁▃▂▆▄▂▄▅▂▂▂▅▇▃▃▃▃▄█▅▃▃▆▆▅▅▄▃▃▆▂</td></tr><tr><td>ppo_loss</td><td>▃▆▄▄▅▆▆▅▁▂▆▄▇▄▄▂▆▃█▁▃▁▄▂▅▅▄▁▅▆▃█▄▄▄▅▃▅▂▆</td></tr><tr><td>reward</td><td>▇▇▅▄▇▇▄▃▇▇▆▇█▇▄▄▇▅▇▄▆▄▇▇▇▇▇▅▁▇██▃▃█▄▅▇▇▁</td></tr><tr><td>reward_per_piece</td><td>▇▇▅▇▆▆▆▇▆▆▅▇█▇▆▄▃▇▇▇█▄▇▆▅▇▆▇▇▇▇▆▇▇▇▅▁▇▇▆</td></tr><tr><td>unclipped_proportion</td><td>▄▅█▂▃▄▄▄▂▆▆▅▅▃▅▂▅▃▂▁▆▆▁▅▂▄▆▅▇▂▄▄▁▄▄▆▂▆▄▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>critic_loss</td><td>5.3345</td></tr><tr><td>entropy</td><td>-0.10619</td></tr><tr><td>kl_div</td><td>0.36793</td></tr><tr><td>ppo_loss</td><td>0.03429</td></tr><tr><td>reward</td><td>59.595</td></tr><tr><td>reward_per_piece</td><td>0.11685</td></tr><tr><td>unclipped_proportion</td><td>0.935</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bright-pyramid-400</strong> at: <a href='https://wandb.ai/michaelsherrick/Tetris/runs/v1j32fwm' target=\"_blank\">https://wandb.ai/michaelsherrick/Tetris/runs/v1j32fwm</a><br/> View project at: <a href='https://wandb.ai/michaelsherrick/Tetris' target=\"_blank\">https://wandb.ai/michaelsherrick/Tetris</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 3068 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241215_102940-v1j32fwm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.wandb_run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b28431-58af-4c0b-bf24-e011ae0e1bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
